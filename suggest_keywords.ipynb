{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # just to ingore gensim deprecated numpy conversion warning\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import string\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_path = Path('./fasttext.model').absolute()\n",
    "    # fasttext_model300 = api.load('fasttext-wiki-news-subwords-300') # download pretrained model from internet\n",
    "    fname = get_tmpfile(model_path)\n",
    "    # fasttext_model300.save(fname) # save pretrained model from internet to current directory\n",
    "    # print('model saved to', fname)\n",
    "    print('Loading model from {}...'.format(model_path))\n",
    "    model = KeyedVectors.load(fname) # load model from current directory\n",
    "    print('Model loaded from', fname)\n",
    "    print('\\n')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_single_prediction(pred_text, model, no_preds=15):\n",
    "    # helper function for single word predictions\n",
    "    # we will split mulitple words into a series of single words and run them through this function\n",
    "    print('Keywords closely related to \\\"{}\\\":'.format(pred_text))\n",
    "    print(model.most_similar(pred_text, topn=no_preds))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pred_text, model):\n",
    "    # top-level predict function for all predictions\n",
    "    if pred_text in model.vocab: # Predicting Word in Vocab\n",
    "        print_single_prediction(pred_text, model)\n",
    "        return\n",
    "    else: # Predicting phrase\n",
    "        print('\\\"{}\\\" is not in vocab; splitting into multiple words...\\n'.format(pred_text))\n",
    "        for char in pred_text:\n",
    "            if char in string.punctuation: # error checking for strings like dui_lawyer\n",
    "                pred_text = outside_pred.replace(char, ' ')\n",
    "\n",
    "    split_pred_text = pred_text.split(' ')\n",
    "    no_pred_words = []\n",
    "    for word in split_pred_text:\n",
    "        if word in model.vocab:\n",
    "            print_single_prediction(word, model)\n",
    "        else:\n",
    "            no_pred_words.append(word)\n",
    "\n",
    "    for word in no_pred_words:\n",
    "        print('\\nNo predictions found for \\\"{}\\\". Please try another word.\\n'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get new keyword suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from C:\\Users\\lewys\\Documents\\Freelance\\suggest-keywords\\fasttext.model...\n",
      "Model loaded from C:\\Users\\lewys\\Documents\\Freelance\\suggest-keywords\\fasttext.model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now give the predict function a string and loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"divorce lawyer\" is not in vocab; splitting into multiple words...\n",
      "\n",
      "Keywords closely related to \"divorce\":\n",
      "[('divorces', 0.8392422199249268), ('pre-divorce', 0.8014459609985352), ('post-divorce', 0.7984651327133179), ('marriage', 0.7579370737075806), ('divorcing', 0.757463812828064), ('remarriage', 0.7570939064025879), ('re-marriage', 0.7552791237831116), ('postdivorce', 0.735708475112915), ('divorcement', 0.720141589641571), ('divorce-related', 0.7192463874816895), ('divorce.', 0.7122068405151367), ('annulment', 0.6923553943634033), ('divorc√©s', 0.6922506093978882), ('divorced', 0.6849225759506226), ('Divorce', 0.6791139841079712)]\n",
      "\n",
      "Keywords closely related to \"lawyer\":\n",
      "[('attorney', 0.8739438056945801), ('ex-lawyer', 0.7932926416397095), ('lawyers', 0.7913783192634583), ('non-lawyer', 0.784548819065094), ('nonlawyer', 0.782863438129425), ('solicitor', 0.7826274633407593), ('attorney-at-law', 0.7760663032531738), ('litigator', 0.772079348564148), ('non-attorney', 0.748200535774231), ('attorneys', 0.7443004250526428), ('client-lawyer', 0.7419846653938293), ('lawyer.', 0.7386767864227295), ('anti-lawyer', 0.7359532117843628), ('prosecutor', 0.7240240573883057), ('jurist', 0.7167099714279175)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_string = \"divorce lawyer\"\n",
    "predict(input_string, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
